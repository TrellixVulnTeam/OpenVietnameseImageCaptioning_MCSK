## configuration for paths
path:
  train_json_path : features/annotations/UIT-ViIC/uitviic_captions_train2017.json
  dev_json_path : features/annotations/UIT-ViIC/uitviic_captions_val2017.json
  public_test_json_path : features/annotations/UIT-ViIC/uitviic_captions_test2017.json
  private_test_json_path: features/annotations/vieCap4H/viecap4h_captions_private_test2017.json
  image_features_path : features/region_features/UIT-ViIC/faster_rcnn
  images_path : null

## configuration for training
training:
  checkpoint_path: saved_models
  start_from: null
  learning_rate: 1.0
  warmup: 10000
  xe_base_lr: 0.0001
  rl_base_lr: 0.000005
  refine_epoch_rl: 28
  get_scores: False
  training_beam_size: 5
  evaluating_beam_size: 5
  using_features: grid

## model configuration
model:
  name: dlct_transformer
  nhead : 8
  nlayers : 3
  d_model : 512
  d_k : 64
  d_v : 64
  d_ff : 2048
  d_feature : 2048
  dropout : .5
  embedding_dim : 300

  transformer:
    encoder:
      args:
        use_aoa: False
        multi_level_output: False
      module: dlct-encoder

    decoder:
      args:
        use_aoa: False
        ## pretrained language model components
        pretrained_language_model_name : vinai/phobert-base
        pretrained_language_model : phobert-base
        pretrained_language_model_path : best_language_model.pth
        language_model_hidden_size : 768
      module: decoder

## dataset configuration
dataset:
  batch_size: 32
  workers: 2
  tokenizer: null
  word_embedding: null
  min_freq: 1